{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Greeting\n",
      "0     Hello, World!\n",
      "1  Hello, Universe!\n",
      "2    Hello, Galaxy!\n",
      "3      Hello there!\n",
      "4        Hi, World!\n",
      "5     Hi, Universe!\n",
      "6       Hi, Galaxy!\n",
      "7         Hi there!\n",
      "8        Greetings!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../data/hello_world_dataset.csv')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert greetings to numerical labels\n",
    "greetings = df['Greeting'].unique()\n",
    "greeting_to_label = {greeting: label for label, greeting in enumerate(greetings)}\n",
    "df['Label'] = df['Greeting'].map(greeting_to_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Hello, World!']\n",
      " ['Hello, Universe!']\n",
      " ['Hello, Galaxy!']\n",
      " ['Hello there!']\n",
      " ['Hi, World!']\n",
      " ['Hi, Universe!']\n",
      " ['Hi, Galaxy!']\n",
      " ['Hi there!']\n",
      " ['Greetings!']]\n"
     ]
    }
   ],
   "source": [
    "# Split data into features and labels\n",
    "X = df['Greeting'].values.reshape(-1, 1)  # Features (reshape for OneHotEncoder)\n",
    "y = df['Label'].values                     # Labels\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode the features\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "print(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network\n",
    "class SimpleNeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Initialize weights and biases\n",
    "        self.weights1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "        self.bias1 = np.zeros((1, hidden_size))\n",
    "        self.weights2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "        self.bias2 = np.zeros((1, output_size))\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # For numerical stability\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Forward propagation\n",
    "        self.hidden_input = np.dot(X, self.weights1) + self.bias1\n",
    "        self.hidden_output = self.sigmoid(self.hidden_input)\n",
    "        self.output_input = np.dot(self.hidden_output, self.weights2) + self.bias2\n",
    "        self.output = self.softmax(self.output_input)\n",
    "        return self.output\n",
    "\n",
    "    def train(self, X, y, epochs=1000, learning_rate=0.1):\n",
    "        for epoch in range(epochs):\n",
    "            # Forward pass\n",
    "            output = self.forward(X)\n",
    "\n",
    "            # Compute loss (cross-entropy)\n",
    "            m = y.shape[0]\n",
    "            log_probs = -np.log(output[range(m), y])\n",
    "            loss = np.sum(log_probs) / m\n",
    "\n",
    "            # Backpropagation\n",
    "            d_output = output\n",
    "            d_output[range(m), y] -= 1\n",
    "            d_output /= m\n",
    "\n",
    "            d_hidden = np.dot(d_output, self.weights2.T) * (self.hidden_output * (1 - self.hidden_output))\n",
    "\n",
    "            # Update weights and biases\n",
    "            self.weights2 -= learning_rate * np.dot(self.hidden_output.T, d_output)\n",
    "            self.bias2 -= learning_rate * np.sum(d_output, axis=0, keepdims=True)\n",
    "            self.weights1 -= learning_rate * np.dot(X.T, d_hidden)\n",
    "            self.bias1 -= learning_rate * np.sum(d_hidden, axis=0, keepdims=True)\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        output = self.forward(X)\n",
    "        return np.argmax(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.1974256417505362\n",
      "Epoch 100, Loss: 2.1970669073931957\n",
      "Epoch 200, Loss: 2.1968775208219378\n",
      "Epoch 300, Loss: 2.1965807209948083\n",
      "Epoch 400, Loss: 2.1960838749706766\n",
      "Epoch 500, Loss: 2.1952319085063503\n",
      "Epoch 600, Loss: 2.193759074399563\n",
      "Epoch 700, Loss: 2.191207282999569\n",
      "Epoch 800, Loss: 2.186787919785439\n",
      "Epoch 900, Loss: 2.1791517631240023\n"
     ]
    }
   ],
   "source": [
    "# Create and train the neural network\n",
    "input_size = X_encoded.shape[1]  # Number of input features (one-hot encoded)\n",
    "output_size = len(greetings)     # Number of unique greetings\n",
    "nn = SimpleNeuralNetwork(input_size, hidden_size=10, output_size=output_size)\n",
    "nn.train(X_encoded, y, epochs=1000, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prediction\n",
    "new_greeting = \"Hello, World!\"\n",
    "new_greeting_encoded = encoder.transform(np.array([new_greeting]).reshape(-1, 1))\n",
    "predicted_label = nn.predict(new_greeting_encoded)\n",
    "predicted_greeting = greetings[predicted_label[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted greeting: Hello, World!\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted greeting: {predicted_greeting}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
